#
import streamlit as st
from PIL import Image 
#Importation de packages
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import requests
from joblib import dump
import math
import os
import shap

df = pd.read_csv("Fichier_de_base.csv")
df_21 =pd.read_csv("Fichier_2021.csv")
df2 = pd.read_csv("climate_change_indicators.csv", sep=";")  


# ---------------- Menu principal ----------------
st.sidebar.title("üåü Menu Principal")
menu = st.sidebar.radio("üìå Naviguer vers :", ["CV", "Projet"])

# ---------------- Section CV ----------------
if menu == "CV":
    st.title("üìÑ CV Interactif - Yacine KHELIFA")
    st.write("Bienvenue dans mon CV interactif. Naviguez ci-dessous pour d√©couvrir mon parcours complet.")

    # Onglets horizontaux pour une organisation claire du CV
    tab_selected = st.selectbox(
        "üåü S√©lectionnez une section :",
        ["üèÜ Lettre de Motivation", "üìÇ Exp√©riences", "üõ†Ô∏è Comp√©tences", "üéì Formations", "üìû Contact"]
    )

    # ---------------- Lettre de Motivation ----------------
    if tab_selected == "üèÜ Lettre de Motivation":
        st.header("Lettre de Motivation")
        st.write("""
        **Objet** : Candidature au poste de Data Analyst

        Madame, Monsieur,  
        Passionn√© par l‚Äôanalyse de donn√©es et dipl√¥m√© d‚Äôune formation sp√©cialis√©e chez Datascientest.com, 
        je ma√Ætrise des outils comme Python, SQL et Power BI, que j‚Äôai utilis√©s dans plusieurs projets 
        pour transformer des donn√©es complexes en insights exploitables.  

        Mon exp√©rience en suivi de raccordement de la fibre optique m‚Äôa permis de d√©velopper 
        des tableaux de bord interactifs et des indicateurs cl√©s de performance, am√©liorant la prise de d√©cision 
        et la satisfaction client.  

        Rejoindre votre √©quipe serait une opportunit√© de mettre √† profit mes comp√©tences techniques et 
        humaines pour contribuer √† vos projets innovants. Je suis convaincu que ma polyvalence et 
        ma capacit√© d‚Äôadaptation seront des atouts pr√©cieux pour votre organisation.

        Cordialement,  
        **Yacine KHELIFA**
        """)

    # ---------------- Exp√©riences ----------------
    elif tab_selected == "üìÇ Exp√©riences":
        st.header("Exp√©riences Professionnelles")
        st.markdown("""
        ### B√©n√©vole - Reclaim Finance, Paris (Depuis 10.2024)
        - Recherche et collecte de donn√©es sur des sites identifi√©s.  
        - Consolidation et traitement de donn√©es au format Excel.  

        ### Suivi de raccordement fibre optique - Orange (Depuis 06.2021)
        SERVICE ACCUEIL PRESTIGE, Paris Depuis 06.2021
        - Pilot√© le d√©ploiement de fi bre optique en analysant lesdonn√©es de couverture et de progression dans diversesr√©gions.
        - Assur√© le suivi des performances et le respect des d√©laisen utilisant des indicateurs cl√©s de performance (KPI).
        - Mis en place des contr√¥les qualit√© bas√©s sur l'analyse desretours clients et des donn√©es de satisfaction pour garantirune am√©lioration continue.
        - Cr√©√© des visualisations et des tableaux de bord interactifspour suivre les performances en temps r√©el et faciliter laprise de d√©cision.
                           

        ### Conseil en gestion h√¥teli√®re - Service Accueil Prestige (01.2018 - 05.2021)
        - Dirig√© une √©quipe conseillant l'industrie h√¥teli√®re.
        - D√©velopp√© des strat√©gies marketing innovantes, augmentant l'occupation h√¥teli√®re.
        - √âtabli des partenariats pour r√©duire les co√ªts tout enmaintenant la qualit√©.
        - Cr√©√© des visualisations et des rapports interactifs poursuivre l'impact des strat√©gies marketing et optimiser lesd√©cisions commerciales.
                
        ### Coordonnateur services client - H√¥tel Le Cheval Noir, Pantin (06.2016 - 08.2017)
        - G√©r√© effi cacement les op√©rations quotidiennes del'accueil, y compris la planifi cation des quarts de travail etla coordination des t√¢ches du personnel.
        - Mis en place des processus de suivi de la satisfactionclient et des commentaires, permettant d'identifi er lesdomaines d'am√©lioration.
        - D√©velopp√© des tableaux de bord pour suivre lesindicateurs de satisfaction et ajuster les services encons√©quence, optimisant ainsi l'effi cacit√© et l'exp√©rienceclient.""")
                    
    # ---------------- Comp√©tences ----------------
    elif tab_selected == "üõ†Ô∏è Comp√©tences":
        st.header("Comp√©tences Techniques")
        st.markdown("""
        - **Python pour les analystes de donn√©es** : 
        Utilisation approfondie de Python pour l'extraction dedonn√©es, le nettoyage, l'analyse et la visualisation, entirant parti de biblioth√®ques telles que Pandas et NumPy. 
                     
        - **SQL pour la science des donn√©es** : 
        Techniques avanc√©es de requ√™tage SQL pour manipuler etinterroger des bases de donn√©es relationnelles,essentielles pour l'extraction et la manipulation de donn√©es √† grande √©chelle.  
                    
        - **Analyse de donn√©es** : 
        Comp√©tences en nettoyage, transformation et analyse degrands ensembles de donn√©es pour en extraire des insights et des tendances pertinentes, utilisant des outils statistiques et algorithmiques.
                    
        - **Qualit√© des donn√©es** : 
        Expertise dans l'√©valuation de la pr√©cision, la compl√©tude,la validit√© et la coh√©rence des donn√©es, ainsi que dans l'impl√©mentation de strat√©gies pour am√©liorer la qualit√© des donn√©es collect√©es ou g√©n√©r√©es.
                    
        - *Visualisation des donn√©es avec Seaborn** : 
        Capacit√© √† cr√©er des visualisations avanc√©es et esth√©tiquement plaisantes pour interpr√©ter les donn√©esde mani√®re intuitive, utilisant Seaborn en combinaison avec Python.
                    
        - **Matplotlib en Python** : 
        Comp√©tences techniques pour g√©n√©rer des graphiques statiques, interactifs et anim√©s avec Matplotlib, adapt√©s pour des analyses et des pr√©sentations de donn√©es.  
                    
        - **Statistiques exploratoires avec Python** : 
        Utilisation des m√©thodes statistiques exploratoires pouranalyser et interpr√©ter des ensembles de donn√©es, permettant une compr√©hension approfondie des variables et des relations entre elles.

        - **Clustering avec scikit-learn** :
        Ma√Ætrise des techniques de regroupement des donn√©es utilisant scikit-learn pour identifier des sous-ensembles significatifs et des mod√®les cach√©s dans des ensembles de donn√©es complexes.
                    

        - **Apprentissage automatique avec sklearn** :
        D√©veloppement et d√©ploiement de mod√®les de machine learning, y compris la r√©gression, la classification, et le clustering, en utilisant la biblioth√®que scikit-learn.
                    
        - **Certifi cation Make (Integromat)** : 
        Comp√©tences en automatisation des processus entre applications web via Make (anciennement Integromat), permettant de cr√©er des flux de travail automatis√©s et int√©gr√©s.
                    

        - **Pipeline (FR)** : 
        Conception et gestion de pipelines de donn√©es robustes pour le traitement et l'analyse des donn√©es, en assurant l'int√©grit√© et la disponibilit√© des donn√©es tout au long des processus.


        - **Power BI** : 
        Comp√©tences avanc√©es dans la cr√©ation et la gestion de dashboards et rapports interactifs avec Power BI pour le reporting d'entreprise et l'analyse d√©cisionnelle.
                    
       
        - **Text Mining** : 
        Techniques de fouille de texte pour l'extraction de donn√©es, l'analyse de sentiments, et la classification de documents, utilisant des outils de traitement du langage naturel.
        
        - **Web Scraping avec BeautifulSoup** : 
        Techniques pour extraire des donn√©es de sites web enutilisant BeautifulSoup, permettant de r√©cup√©rer des informations structur√©es √† partir de sources HTML ou XML.
                               


        **Je suis tr√®s motiv√© √† l'id√©e de contribuer avec mon expertise en analyse de donn√©es et mes comp√©tences en visualisation d'informations. J'accueille avec enthousiasme l'opportunit√© de discuter de la mani√®re dont je pourrais apporter une valeur ajout√©e. Je vous remercie pour votre consid√©ration et esp√®re avoir l'occasion de contribuer√† vos succ√®s futurs.**

        """)

    # ---------------- Formations ----------------
    elif tab_selected == "üéì Formations":
        st.header("Formations")
        st.markdown("""
        ### Data Analyst - DataScientest.com (01.2024 - 09.2024)
        - Formation avanc√©e en analyse de donn√©es,
        - Ma√Ætrise des outils statistiques et des logiciels de data science tels que Python, SQL et Power BI,
        - D√©veloppement de comp√©tences en visualisation de donn√©es,
        - Interpr√©tation de sets complexes,
        - Formulation de solutions bas√©es sur les donn√©es.

        ### Licence Langue et Cultures Amazighes - Universit√© Abderramane Mira (09.2011 - 09.2014)
        - √âtudes approfondies sur la linguistique et la culture.  
        - D√©veloppement de comp√©tences en analyse critique et r√©daction.  

        ### Master 1 G√©ographie Linguistique - Universit√© Abderramane Mira (09.2014 - 06.2015)
        - Visualisation des donn√©es : Cr√©√© des cartes pour repr√©senter lesdonn√©es g√©ographiques et linguistiques de mani√®re claire.
        - √âtude des dialectes : Analy√© les variations dialectales pour comprendreles diff√©rences linguistiques √† travers diverses r√©gions.
        - Standardisation de la langue : Utilis√© les donn√©es sur les variationsdialectales pour soutenir les efforts
    """)
    # ---------------- Contact ----------------
    elif tab_selected == "üìû Contact":
        st.header("Contact")
        st.write("""
        - **T√©l√©phone** : 0641346278  
        - **Email** : [yacine.metal@hotmail.com](mailto:yacine.metal@hotmail.com)  
        - **LinkedIn** : [linkedin.com/in/yacine-khelifa](https://linkedin.com/in/yacine-khelifa)  
        - **GitHub** : [github.com/khelifaYacine](https://github.com/khelifaYacine)  
        """)

    # Lien de t√©l√©chargement du CV
        with open("CV Yacine KHELIFA Data Analyst.pdf", "rb") as file:
          st.download_button(label="üì• T√©l√©charger le CV (PDF)", data=file, file_name="CV Yacine KHELIFA Data Analyst.pdf", mime="application/pdf")
    

# ---------------- Section Projet ----------------
elif menu == "Projet":
    st.title("üìä Analyse des Donn√©es du Bonheur")
    st.write("""
    Explorez les indicateurs du bonheur mondial √† travers ce projet interactif.  
    Naviguez dans les √©tapes pour d√©couvrir l'analyse compl√®te.
    """)

    # Navigation verticale pour la section projet
    st.sidebar.title("Sommaire du Projet")
    pages = ["Exploration", "Data Visualisation", "Pr√©processing", "Mod√©lisation", "Interpr√©tabilit√©"]
    page = st.sidebar.radio("√âtapes du Projet", pages)

    if page == "Exploration":
        st.header("üîç Exploration des Donn√©es")
        st.write("# ANALYSE DU BIEN ETRE SUR TERRE")
  # Charger une image √† partir d'un fichier local
        image = "Happiness.png"
  # Afficher l'image sur l'application Streamlit
        st.image(image, caption='Les cl√©s du bonheur', use_column_width=True)

        st.write("## Introduction")
        st.write ("Ce projet vise √† conduire une analyse approfondie des donn√©es du World Happiness Report afin d'√©valuer le bonheur des pays du monde en utilisant une vari√©t√© d'indicateurs socio-√©conomiques tels que la sant√©, la corruption, l'√©conomie et l'esp√©rance de vie.")
        st.write ("L'objectif principal est de pr√©senter ces donn√©es √† travers des visualisations interactives tout en identifiant les combinaisons de facteurs qui expliquent les raisons pour lesquelles certains pays sont mieux class√©s que d'autres en termes de bonheur.")
        st.write("")

  #importer le jeu de donn√©es du 2005 √† 2020. Et 2021
  
        st.write("Affichage des 10 premi√®res lignes du world-happiness-report.csv 2005-2020")
        st.dataframe(df.head(10))
        st.write(df.shape)

#st.write("R√©sum√© statistique des variables num√©riques")
  #st.dataframe(df.describe())  
  
        st.write ("Adjonction des variables 'r√©gion' et 'temp√©rature' √† notre dataset ")
        def get_regional_indicator(country_name):
            country_to_region = {
                "Denmark": "Western Europe",
                "France": "Western Europe",
                "Mexico": "Latin America and Caribbean",
                "Germany": "Western Europe",
                "Poland": "Central and Eastern Europe",
                "Spain": "Western Europe",
                "Greece": "Western Europe",
                "Brazil": "Latin America and Caribbean",
                "Sweden": "Western Europe",
                "Egypt": "Middle East and North Africa",
                "Saudi Arabia": "Middle East and North Africa",
                "Lebanon": "Middle East and North Africa",
                "Netherlands": "Western Europe",
                "Australia": "Australia and New Zealand",
                "United Kingdom": "Western Europe",
                "Canada": "North America",
                "Iran": "Middle East and North Africa",
                "Pakistan": "South Asia",
                "Hungary": "Central and Eastern Europe",
                "Czech Republic": "Central and Eastern Europe",
                "Belgium": "Western Europe",
                "Turkey": "Middle East and North Africa",
                "Jordan": "Middle East and North Africa",
                "Venezuela": "Latin America and Caribbean",
                "Italy": "Western Europe",
                "Japan": "East Asia",
                "Romania": "Central and Eastern Europe",
                "Portugal": "Western Europe",
                "Singapore": "Southeast Asia",
                "Sierra Leone": "Sub-Saharan Africa",
                "Rwanda": "Sub-Saharan Africa",
                "Chile": "Latin America and Caribbean",
                "Senegal": "Sub-Saharan Africa",
                "Russia": "Commonwealth of Independent States",
                "Colombia": "Latin America and Caribbean",
                "Chad": "Sub-Saharan Africa",
                "China": "East Asia",
                "South Korea": "East Asia",
                "Slovenia": "Central and Eastern Europe",
                "Uganda": "Sub-Saharan Africa",
                "Belarus": "Commonwealth of Independent States",
                "Trinidad and Tobago": "Latin America and Caribbean",
                "Togo": "Sub-Saharan Africa",
                "Benin": "Sub-Saharan Africa",
                "Thailand": "Southeast Asia",
                "Tanzania": "Sub-Saharan Africa",
                "Bolivia": "Latin America and Caribbean",
                "Tajikistan": "Commonwealth of Independent States",
                "Taiwan Province of China": "East Asia",
                "Switzerland": "Western Europe",
                "Botswana": "Sub-Saharan Africa",
                "Sri Lanka": "South Asia",
                "Burkina Faso": "Sub-Saharan Africa",
                "Cambodia": "Southeast Asia",
                "South Africa": "Sub-Saharan Africa",
                "Cameroon": "Sub-Saharan Africa",
                "Slovakia": "Central and Eastern Europe",
                "Philippines": "Southeast Asia",
                "Costa Rica": "Latin America and Caribbean",
                "Cuba": "Latin America and Caribbean",
                "Malawi": "Sub-Saharan Africa",
                "Madagascar": "Sub-Saharan Africa",
                "Guatemala": "Latin America and Caribbean",
                "Lithuania": "Central and Eastern Europe",
                "Haiti": "Latin America and Caribbean",
                "Latvia": "Central and Eastern Europe",
                "Honduras": "Latin America and Caribbean",
                "Malaysia": "Southeast Asia",
                "Laos": "Southeast Asia",
                "Kyrgyzstan": "Commonwealth of Independent States",
                "Kuwait": "Middle East and North Africa",
                "Kenya": "Sub-Saharan Africa",
                "India": "South Asia",
                "Kazakhstan": "Commonwealth of Independent States",
                "Indonesia": "Southeast Asia",
                "Jamaica": "Latin America and Caribbean",
                "Ireland": "Western Europe",
                "Hong Kong S.A.R. of China": "East Asia",
                "Ghana": "Sub-Saharan Africa",
                "Mali": "Sub-Saharan Africa",
                "Georgia": "Commonwealth of Independent States",
                "Cyprus": "Middle East and North Africa",
                "Paraguay": "Latin America and Caribbean",
                "Panama": "Latin America and Caribbean",
                "Palestinian Territories": "Middle East and North Africa",
                "Bangladesh": "South Asia",
                "Dominican Republic": "Latin America and Caribbean",
                "Norway": "Western Europe",
                "Ecuador": "Latin America and Caribbean",
                "Nigeria": "Sub-Saharan Africa",
                "Niger": "Sub-Saharan Africa",
                "Nicaragua": "Latin America and Caribbean",
                "El Salvador": "Latin America and Caribbean",
                "New Zealand": "Australia and New Zealand",
                "Estonia": "Central and Eastern Europe",
                "Nepal": "South Asia",
                "Mozambique": "Sub-Saharan Africa",
                "Finland": "Western Europe",
                "Moldova": "Commonwealth of Independent States",
                "Peru": "Latin America and Caribbean",
                "Ukraine": "Commonwealth of Independent States",
                "Israel": "Middle East and North Africa",
                "Azerbaijan": "Commonwealth of Independent States",
                "Vietnam": "Southeast Asia",
                "Uruguay": "Latin America and Caribbean",
                "Zimbabwe": "Sub-Saharan Africa",
                "Armenia": "Commonwealth of Independent States",
                "Austria": "Western Europe",
                "Argentina": "Latin America and Caribbean",
                "United States": "North America",
                "Zambia": "Sub-Saharan Africa",
                "United Arab Emirates": "Middle East and North Africa",
                "Uzbekistan": "Commonwealth of Independent States",
                "Liberia": "Sub-Saharan Africa",
                "Bosnia and Herzegovina": "Central and Eastern Europe",
                "Montenegro": "Central and Eastern Europe",
                "Croatia": "Central and Eastern Europe",
                "Central African Republic": "Sub-Saharan Africa",
                "Mongolia": "East Asia",
                "Bulgaria": "Central and Eastern Europe",
                "Albania": "Central and Eastern Europe",
                "Mauritania": "Sub-Saharan Africa",
                "Yemen": "Middle East and North Africa",
                "Kosovo": "Central and Eastern Europe",
                "Serbia": "Central and Eastern Europe",
                "North Macedonia": "Central and Eastern Europe",
                "Belize": "Latin America and Caribbean",
                "Guyana": "Latin America and Caribbean",
                "Namibia": "Sub-Saharan Africa",
                "Afghanistan": "South Asia",
                "Djibouti": "Sub-Saharan Africa",
                "Congo (Brazzaville)": "Sub-Saharan Africa",
                "Iceland": "Western Europe",
                "Iraq": "Middle East and North Africa",
                "Syria": "Middle East and North Africa",
                "Burundi": "Sub-Saharan Africa",
                "Congo (Kinshasa)": "Sub-Saharan Africa",
                "Qatar": "Middle East and North Africa",
                "Ivory Coast": "Sub-Saharan Africa",
                "Tunisia": "Middle East and North Africa",
                "Turkmenistan": "Commonwealth of Independent States",
                "Comoros": "Sub-Saharan Africa",
                "Bahrain": "Middle East and North Africa",
                "Somaliland region": "Sub-Saharan Africa",
                "Luxembourg": "Western Europe",
                "Malta": "Western Europe",
                "Sudan": "Sub-Saharan Africa",
                "Algeria": "Middle East and North Africa",
                "Morocco": "Middle East and North Africa",
                "Swaziland": "Sub-Saharan Africa",
                "Guinea": "Sub-Saharan Africa",
                "Lesotho": "Sub-Saharan Africa",
                "Oman": "Middle East and North Africa",
                "Angola": "Sub-Saharan Africa",
                "Gabon": "Sub-Saharan Africa",
                "Mauritius": "Sub-Saharan Africa",
                "Myanmar": "Southeast Asia",
                "North Cyprus": "Western Europe",
                "Suriname": "Latin America and Caribbean",
                "Libya": "Middle East and North Africa",
                "Ethiopia": "Sub-Saharan Africa",
                "Bhutan": "South Asia",
                "Somalia": "Sub-Saharan Africa",
                "South Sudan": "Sub-Saharan Africa",
                "Gambia": "Sub-Saharan Africa",
                "Maldives": "South Asia"
            }
            if country_name in country_to_region:
                return country_to_region[country_name]
            else:
                return "Unknown"
        # Ajouter une colonne "Regional indicator" dans le DataFrame
        df["Regional indicator"] = df["Country name"].apply(get_regional_indicator)
        # Renommage des colonnes
        df_a_renamed = df2.rename(columns={'NMGB': 'Country name', 'Year': 'year'})
        # Fusion des DataFrames
        df = pd.merge(df, df_a_renamed[['Country name', 'year', 'Temperature']], on=['Country name', 'year'], how='left')
        st.dataframe(df.head())
        # Enregistrement du DataFrame dans un fichier CSV
        df.to_csv('fichier_concat.csv', index=False)

        
        if st.checkbox("Afficher les NA") :
            st.dataframe(df.isna().sum()) 








    elif page == "Data Visualisation":
        st.header("üìä Visualisation des Donn√©es")
        st.write("Graphiques interactifs pour analyser les tendances...")

        st.write ("### Distribution du score du bonheur des pays")
        fig = plt.figure()
        sns.histplot(df ["Life Ladder"], kde=True, bins=10, color="g", edgecolor="black")
        plt.title("Distribution du Life Ladder")
        plt.xlabel("Life Ladder")
        plt.ylabel("Fr√©quence") 
        # Calculer la m√©diane
        median_value = df["Life Ladder"].median()
        # Ajouter la ligne de m√©diane
        plt.axvline(x=median_value, color="red", linestyle="--", label="M√©diane")
        # Afficher le graphique avec la l√©gende
        plt.legend()
        st.pyplot(fig)

        #st.write ("### Interpr√©tation :")
        st.write ("0 le moins heureux et 8 le plus heureux.")
        #st.write ("- Graphe , avec une queue plus longue vers la gauche. Cela indique qu‚Äôil y a plus de gens qui ont un score de bonheur inf√©rieur √† la moyenne que sup√©rieur √† la moyenne.")
        st.write ("")
        st.write ( "### Boxplot du score du bonheur par ann√©es")
        fig = plt.figure()
        # S√©lectionner les variables cat√©gorielles
        variables_cat√©gorielles = [ "year"]

        # Tracer des boxplots pour chaque variable cat√©gorielle
        for variable in variables_cat√©gorielles:
        
            sns.boxplot(x=variable, y="Life Ladder", data=df)
            plt.title(f"Boxplot Ladder score by {variable}")
            plt.xlabel(variable)
            plt.ylabel("Ladder score")
            plt.xticks(rotation=45)
            
        st.pyplot(fig)
        
        st.write ("")
        #st.write ("### Interpr√©tation :")
        st.write ("L√©g√®re augementation au fil des ann√©es")
        st.write ("Quelques valeurs aberrantes en 2020")

        st.write ("")
        st.write ("")
        st.write ("## Matrice de correlation par heatmap")
        #Affichage de la matrice de corr√©lation par heatmap
        # df_base_numeric = df.select_dtypes(include=['float64', 'int64'])
        # Calcul de la matrice de corr√©lation
        # corr_matrix = df_base_numeric.corr()
        # Charger une image √† partir d'un fichier local
        image2 = "Heatmap.png"
        # Afficher l'image sur l'application Streamlit
        st.image(image2, use_column_width=True)
        
        st.write("")

        st.write ("### Boxenplot du score du bonheur par r√©gion")
        fig = plt.figure ()
        sns.boxenplot(x="Life Ladder", y= "Regional indicator", data = df2)
        plt.title("Distribution des scores de bonheur par r√©gion")
        plt.xlabel("Score de bonheur")
        plt.ylabel("R√©gion")
        st.write(fig)

        st.write("")
        #st.write ("### comparaison de Life Ladder and Log GDP per capita par pays et par ann√©es")
        fig = plt.figure ()
        import plotly.express as px

        # Tracer le nuage de points interactif avec Plotly Express
        df = df.sort_values('year')
        fig = px.scatter(df,
                        x="Log GDP per capita",
                        y="Life Ladder",
                        animation_frame="year",
                        animation_group="Country name",

                        color="Social support",
                        hover_name="Country name",
                        size_max=200,
                        template="plotly_white")

        # Mettre √† jour le titre du graphique
        fig.update_layout(title="Scrore du bonheur et PIB par pays selon l'ann√©e")

        # Afficher le graphique
        st.write(fig)

        st.write("")
        st.write ("### Life Ladder par pays selon l'ann√©e")
        fig = plt.figure ()
        fig = px.choropleth(df.sort_values("year"),
                        locations="Country name",
                        color="Life Ladder",
                        locationmode="country names",
                        animation_frame="year")
        fig.update_layout(title="Comparaison du Life Ladder par pays")

        st.write(fig)
        st.write ("")
        
        st.write("### Analyse du facteur climat")

        image3 = "Nuage_Temperature.png"
        # Afficher l'image sur l'application Streamlit
        st.image(image3, use_column_width=True)

    
    

    elif page == "Pr√©processing":
        st.header("‚öôÔ∏è Pr√©processing")
        st.write("Traitement des donn√©es manquantes et pr√©paration des variables.")

        missing = pd.read_csv ("fichier_concat.csv")    


        st.write ("# PREPROCESSING")
        # Pr√©sentation des valeurs manquantes
        st.write("## Traitement des valeurs manquantes")
        st.write("### Aper√ßu des valeurs manquantes dans notre dataset")
        
        # Afficher les valeurs manquantes
        st.write (missing.isnull().sum())

        # Scraping des donn√©es manquantes
        st.write("### 1. Scraping des donn√©es manquantes")
        st.write("Utilisation de l'API de la banque mondiale pour r√©cuprer certaines valeurs manquantes de la variable 'Log GDP per capita'. ")
        #st.write("Pour la variable `Log GDP per capita`, nous avons utilis√© une API pour r√©cup√©rer certaines des valeurs manquantes. L'API utilis√©e est celle de la Banque mondiale. Cela a constitu√© un avantage majeur, car nous avons pu combler directement plusieurs lacunes dans notre dataset, sans devoir estimer toutes les valeurs de mani√®re indirecte.")
        
        # Exemple de code pour scraper les donn√©es (si disponible)
        st.code("""
    import requests

    # Exemple de code pour r√©cup√©rer les donn√©es manquantes
    url = "https://api.worldbank.org/v2/country/all/indicator/NY.GDP.PCAP.CD?format=json"
    response = requests.get(url)
    data = response.json()
    # Extraire les donn√©es n√©cessaires et les int√©grer dans le dataset
        """, language='python')
        

        # Estimation des valeurs manquantes par r√©gression lin√©aire
        st.write("### 2. Estimation des valeurs manquantes par r√©gression lin√©aire")
        st.write("Utilisation d'estimations par r√©gression lin√©aire pour les variables qui n'ont pas pu √™tre obtenues via l'API")
        #st.write("Pour les donn√©es que nous n'avons pas pu obtenir via l'API, nous avons utilis√© une m√©thode d'estimation par r√©gression lin√©aire. Cette technique a permis de combler les valeurs manquantes en utilisant les donn√©es historiques disponibles pour chaque pays.")
        
        # Exemple de code pour la r√©gression lin√©aire
        st.code("""
    # Exemple simple de r√©gression lin√©aire pour estimer des valeurs manquantes
    for column in df.columns:
        if df[column].isnull().sum() > 0:
            X = df.dropna()[['Year']]  # Par exemple, en utilisant l'ann√©e comme variable explicative
            y = df.dropna()[column]
            model = LinearRegression().fit(X, y)
            df.loc[df[column].isnull(), column] = model.predict(df.loc[df[column].isnull(), ['Year']])
        """, language='python')

        # Imputation par KNN
        st.write("### 3. Imputation par KNN")
        st.write("Lorsque la r√©gression lin√©aire n'√©tait pas suffisante nous avons appliqu√© une m√©thode d'imputation par K-nearest neighbors (KNN).")
        #st.write("Pour certaines variables o√π la r√©gression lin√©aire n'√©tait pas suffisante, nous avons appliqu√© une m√©thode d'imputation par K-nearest neighbors (KNN).")
        
        # Exemple de code pour l'imputation par KNN
        st.code("""
    # Imputation par KNN
    imputer = KNNImputer(n_neighbors=5)
    df_knn = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
        """, language='python')

        # Encodage des variables cat√©gorielles
        st.write("## Encodage des variables cat√©gorielles")
        st.write("Une fois les valeurs manquantes trait√©es, nous avons proc√©d√© √† l'encodage des variables cat√©gorielles afin de pr√©parer les donn√©es pour les mod√®les de machine learning.")
        
        # Exemple de code pour l'encodage
        st.code("""
    # One-Hot Encoding
    encoder = OneHotEncoder()
    encoded_vars = encoder.fit_transform(df[['Country name', 'Regional indicator']])
    df_encoded = pd.concat([df.drop(columns=['Country name', 'Regional indicator']), pd.DataFrame(encoded_vars.toarray(), columns=encoder.get_feature_names_out())], axis=1)
        """, language='python')

        
            
        if st.checkbox(" ### Afficher le jeu de donn√©es apr√®s encodage") :
           final = pd.read_csv ("mon_fichier.csv")
           st.dataframe (final.isna().sum())
           st.dataframe(final)

    # Standardiastion
        st.write("## Strandardisation des variables num√©riques par StandardScaler")

        st.write("Ces √©tapes nous ont permis de finaliser notre dataset, qui est d√©sormais pr√™t pour la phase de mod√©lisation.")










    elif page == "Mod√©lisation":
        st.header("ü§ñ Mod√©lisation")
        st.write("Construction et √©valuation des mod√®les pr√©dictifs.")

# Scrapping de la variable "Log GDP per capita"
    ## Modelesations
    # D√©finir les features et la target
        df3 = pd.read_csv("mon_fichier.csv")
        X = df3.drop('Life Ladder', axis=1)  # Toutes les colonnes sauf 'Life Ladder'
        y = df3['Life Ladder']            

        # S√©parer les donn√©es en ensembles d'entra√Ænement et de test
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        #pour streamlit 3
        # D√©finition et entra√Ænement des mod√®les
        def train_model(model_type, params):
            if model_type == 'Linear Regression':
                model = LinearRegression()
            elif model_type == 'Ridge':
                model = Ridge(**params)
            elif model_type == 'Lasso':
                model = Lasso(**params)
            elif model_type == 'Elastic Net':
                model = ElasticNet(**params)
            elif model_type == 'Random Forest':
                model = RandomForestRegressor(**params)
            elif model_type == 'XGBoost':
                model = XGBRegressor(**params)

            model.fit(X_train, y_train)
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)
            mse_train = mean_squared_error(y_train, y_pred_train)
            mse_test = mean_squared_error(y_test, y_pred_test)
            mae_train = mean_absolute_error(y_train, y_pred_train)
            mae_test = mean_absolute_error(y_test, y_pred_test)
            r2_train = r2_score(y_train, y_pred_train)
            r2_test = r2_score(y_test, y_pred_test)

            # Stocker le mod√®le et les donn√©es dans st.session_state pour la page d'interpr√©tabilit√©
            st.session_state['model'] = model
            st.session_state['X_train'] = X_train

            return model, mse_train, mse_test, mae_train, mae_test, r2_train, r2_test

        # Streamlit interface
        model_type = st.selectbox('S√©l√©ctionner le type de mod√®le', ['Linear Regression', 'Ridge', 'Lasso', 'Elastic Net', 'Random Forest', 'XGBoost'])
        params = {}
        if model_type in ['Ridge', 'Lasso', 'Elastic Net']:
            params['alpha'] = st.slider('Alpha', 0.01, 1.0, 0.1)
            if model_type == 'Elastic Net':
                params['l1_ratio'] = st.slider('L1 Ratio', 0.01, 1.0, 0.5)
        if model_type in ['Random Forest', 'XGBoost']:
            params['n_estimators'] = st.slider('Number of Estimators', 10, 300, 100)
            if model_type == 'XGBoost':
                params['learning_rate'] = st.slider('Learning Rate', 0.01, 0.5, 0.1)

        if st.button('Entra√Æner et √©valuer le mod√®le'):
            model, mse_train, mse_test, mae_train, mae_test, r2_train, r2_test = train_model(model_type, params)
            
            # Affichage des r√©sultats sous forme de tableau
            metrics_table = pd.DataFrame({
                'M√©trique': ['MSE', 'MAE', 'R2'],
                'Entra√Ænement': [mse_train, mae_train, r2_train],
                'Test': [mse_test, mae_test, r2_test]
            })

            st.write("### Tableau des scores des m√©triques")
            st.table(metrics_table)

            # Afficher les graphiques
            y_pred = model.predict(X_test)
            fig, ax = plt.subplots()
            ax.scatter(y_test, y_pred, alpha=0.5)
            ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)
            ax.set_xlabel('Valeurs R√©elles')
            ax.set_ylabel('Pr√©dictions')
            ax.set_title('Comparaison des Pr√©dictions et Valeurs R√©elles')
            st.pyplot(fig)







    elif page == "Interpr√©tabilit√©":
        st.header("üìà Interpr√©tabilit√©")
        st.write("Analyse des r√©sultats et des variables importantes.")

    # V√©rifier si le mod√®le a √©t√© entra√Æn√© et stock√© dans st.session_state
        if 'model' not in st.session_state:
            st.write("Aucun mod√®le n'a √©t√© entra√Æn√©. Veuillez entra√Æner un mod√®le sur la page Mod√©lisation.")
        else:
            model = st.session_state['model']
            X_train = st.session_state['X_train']
            X_sample = shap.sample(X_train, 100)
            explainer = shap.Explainer(model, X_sample)
            shap_values = explainer(X_sample)

            st.subheader("Importance des caract√©ristiques")
            fig, ax = plt.subplots()
            shap.summary_plot(shap_values, X_sample, plot_type="bar", show=False)
            st.pyplot(fig)

            #st.subheader("Graphique en nuage de points")
            st.write("")
            st.write("#### La m√©thode SHAP pour le Random Forest nous permet de repr√©senter l‚Äôimportance des variables de notre jeu de donn√©es.") 

            fig, ax = plt.subplots()
            shap.summary_plot(shap_values, X_sample, show=False)
            st.pyplot(fig)

        st.write("### Interpr√©tation des r√©sultats")
        st.markdown("""
        - **Importance des variables** :
        - Le mod√®le Random Forest a identifi√© les variables les plus influentes sur le score de bonheur : "Log GDP per capita", "Social support", et "Healthy life expectancy at birth".
        - Les r√©sultats soulignent l'importance des facteurs √©conomiques et sociaux pour le bien-√™tre des populations.
        """)

        st.write("### Conclusion")
        st.markdown("""
        - **Analyse du bien-√™tre** :
        - L'analyse du World Happiness Report a r√©v√©l√© que les aspects √©conomiques, tels que le PIB par habitant, et les facteurs sociaux, comme le support social et l'esp√©rance de vie, sont cruciaux pour la perception du bonheur.
        - Parmi les mod√®les test√©s, le Random Forest s'est montr√© le plus efficace, avec un R¬≤ de 0.8919 sur les donn√©es de test, capturant bien les relations complexes entre les variables.
        """)

        st.write("")

        st.write("## Perspectives et am√©liorations")
        st.markdown("""
        - Explorer l'impact d'autres variables pour affiner l'√©tude (taux de ch√¥mage, inflation, √©ducation).
        - Estimer le score du bonheur pour l'ann√©e 2021 et le comparer aux donn√©es r√©elles.
        - Optimiser les hyperparam√®tres des mod√®les existants pour am√©liorer les performances de pr√©diction.
        - Int√©grer des mod√®les plus sophistiqu√©s.
        """)

        st.write("")

        st.write("## Int√©r√™ts de l'√©tude")
        st.markdown("""             
        - Analyse globale des facteurs influen√ßant le bonheur mondial.
        - Base pour de futures recherches.
        - Eventuel support d'orientation de strat√©gies politiques.
        """)
        st.write("## Remerciements")
        st.markdown("""             
        Nous tenons √† remercier Yohan et toute l'√©quipe de Datascientest pour leur accompagnement et leur soutien durant ces derniers mois de formation. Votre aide nous a vraiment permis de progresser et d'aller de l'avant. Un grand merci √©galement aux membres du jury pour le temps accord√©.
        """)


        with open("Rapport_Projet_Analyse_Bonheur.pdf", "rb") as file:
            st.download_button(label="üì• T√©l√©charger le Rapport du Projet (PDF)", data=file, file_name="Rapport_Projet_Analyse_Bonheur.pdf", mime="application/pdf")